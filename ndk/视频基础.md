# 视频基础

## 1.视频

由一组图像组成

为了传输/占用更小的空间而被压缩

最终在显示设备上展示(未被压缩)

## 2.图像

由像素组成

## 3.像素

由RGB组成

## 4.分辨率

横向的像素点 * 纵向的像素点

常见的宽高比：16:9   ， 4:3 

目前基本上是16:9，以前方方正正的显示器是4:3的。

360P:640*360

720P:1280*720

1K:

2K:



## 5.RGB

每个像素由3个发光二极管(红、绿、蓝)组成的。

当每个发光二极管显示的亮度不一样时，就会显示不同的颜色。

例：

红+蓝=粉

绿+蓝=青

红+绿=黄

红+绿+蓝=白

## 6.每个像素位深

RGB888（24位）

RGBA(32位)

## 7.屏幕

每个像素都是由3个发光二极管组成(红、绿、蓝)

## 8.图像与屏幕关系

图像是数据

屏幕是显示设备

图像数据经过驱动程序让屏幕显示像素

## 9.RGB色彩问题

RGB与BGR

当遇到颜色不对的时候可能是没有转换成对应的颜色格式。

BMP使用的是BGR格式，需要进行转换

## 10.屏幕指标

PPI (pixels per inch) 每英寸的像素数

说明：表示屏幕的质量，在1寸长的距离内一共放了多少个像素点，像素点越多，密度越大，显示效果更细腻

DPI (Dots pen inch) 每英寸的点数

和PPI很相似，对于有些设备，每英寸的点数包括的可能是多个像素,比较少见



PPI>300 属于视网膜级别，也就是人眼区分不出来。

## 11.帧率

每秒钟 采集/播放 图像的个数

动画的帧率 25帧/s

常见：15帧/s(实时通讯)，30帧/s，60帧/s

## 12.码流的计算

未编码视频RGB码流：

RGB码流=分辨率(宽x高) x 3(Byte) x 帧率

3：RGB

例：1280 x720 x3x 25 =69120000

约69M

通常码流是按位计算，所以要在乘以8：69M * 8位 = 552 M 

也就是1s中552M的数据量

未编码视频YUV码流：

YUV码流 =分辨率(宽x高) x 1.5(Byte) x 帧率



参考：

https://en.wikipedia.org/wiki/YUV



## 13.图像的显示

图像大小等于显示器区域大小

图像小于显示器区域 - 拉伸/留白

图像大于显示器区域 - 缩小/截断

## 14.YUV

YUV（也称YCbCr）：Y表示明亮度，UV是描述影像色彩及饱和度

黑白电视机：只有Y信号

彩色电视机：Y信号和UV信号都有



格式：YUV4:2:0 (标准) , YUV4:2:2 , YUV4:4:4

如果遇到视频播放不出来可能格式不对



为什么视频中YUV被广泛使用：

1.因为视频是从黑白电视机过来的，与以前的兼容

2.YUV比RGB存储更有优势



## 15.RGV与YUV关系

RGB用于屏幕图像的展示

YUV用于采集与编码

## 16.RGB转YUV

Y = 0.299 * R + 0.587 * G' + 0.114 * B

U = -0.147 * R - 0.289 * G + 0.436 * B = 0.492 * (B-Y)

V = 0.615 * R - 0.515 * G - 0.100 * B = 0.877 * (R-Y)

## 17.YUV转RGB

R = Y + 1.140 * V

G = Y - 0.394 * U - 0.581 * V

B = Y + 2.032 * U

## 18.YUV常见格式

YUV4:4:4 ： RGB888相等，1个Y元素，对应1个U元素，对应1个V元素

例：屏幕是1280*720的，1张图片的数据量 = 1280 * 720 * 3

YUV-YUV-YUV-YUV

YUV-YUV-YUV-YUV



YUV4:2:2：每一个横行，隔一个有一个UV

例：屏幕是1280*720的，1张图片的数据量 = 1280 * 720 + 2 * 1280 / 2 * 720 ，相当于减了三分之一的数据量

？？？

YUV-Y-YUV-Y

YUV-Y-YUV-Y



YUV4:2:0：

每一行只有一种色度分量

例:

第一行：Y,Cb -> 4:2:0

第二行：Y,Cr -> 4:0:2

第三行：Y.Cb -> 4:2:0

。。。



YU-Y-YU-Y

YV-Y-YV-Y



计算：

YUV = Y * 1.5

YUV = RGB/2



参考:
https://www.fourcc.org/yuv.php



## 19.YUV存储

分层存储，先Y然后U,V，这样设计原因主要就是黑白电视机的兼容，黑白电视机只要读取Y就可以了

每一个Y的前4项对应1个U和V



![yuv](.\image\yuv.png)

planar（平面）：

I420：YYYYYYYY UU VV => YUV420P

YV12： YYYYYYYY VV UU => YUV420P

packed（打包）：

NV12：YYYYYYYY UVUV => YUV420SP

NV21：YYYYYYYY VUVU => YUV420SP



IOS主要是YV12

Android主要是NV21



## 20.H264压缩比

约 1/100

建议码流：500kbps

参考：

https://docs.agora.io/cn

视频通话-进阶功能-视频管理-设置视频属性



## 21.GOP

Group Of Picture  强相关的一组帧

GOP中帧与帧之间的差别小，可以压缩的非常，这就是GOP意义



## 22.I/P/B帧

I帧(intraframe frame),关键帧，采用帧内压缩技术。



IDR帧属于特殊的I帧。但是I帧并不一定是IDR帧。

一组帧有很多帧，超过一定范围H264会强制加入I帧，防止错误。



P帧(forward Predicted frame)，向前参考帧，只参考前面已经处理的帧。采用帧间压缩技术，它占I帧的一半大小。



B帧(Bidirectionally predicted frame),双向参考帧。压缩时，既参考前面已经处理的帧，也参考后面的帧，帧间压缩技术。它占I帧的四分之一大小。

B帧压缩率最高，但是占用CPU，耗时是最多的。B帧的帧数越多，延迟性就越大，对于实时通讯就不太友好。

所以大部分实时通讯中(音视频会议，在线教育)大量的使用I帧和P帧。

音视频转码会大量使用B帧，为了减少存储空间。



## 23.IDR帧与I帧的区别于联系

IDR（Instantaneous Decoder Refresh）解码器立即刷新。

每当遇到IDR帧时，解码器就会清空解码器参考buffer中的内容。

每个GOP中的第一帧就是IDR帧

IDR帧时一种特殊的I帧



解释说明：

GOP是对于视频若干个分组，分组后每一组之间是有明显的差别的。如果所有视频全都一串播下来，如果中间有错误后面就很难恢复了。有了IDR帧在解码器中缓冲区中所有数据全部清空，清空后找到第一个IDR帧，后边的数据依赖于IDR，这样就防止了错误的传播性。



## 24.SPS与PPS

I帧的一部分，每个IDR前面都会有。

SPS（Sequence Parameter Set）序列参数集，帧组(GOP)的参数设置

作用于一串连续的视频图像（就是GOP）。

如：seq_parameter_set_id、帧数及POC（picture order count）的约束、参考帧数目、解码图像尺寸和帧场编码模式选择表识等。



PPS（Picture Parameter Set）图像参数集

作用于视频序列中的图像

如：pic_parameter_set_id,熵编码模式选择标识、片组数目、初始量化参数和取方法块滤波系数调整标识等

## 25.H264压缩技术

帧内压缩技术：解决空域数据冗余问题(有损压缩)

例：背景是天蓝色的，就能用非常小的数据量存储，解压缩就能用非常小的数据量去还原。



帧间压缩技术：解决时域数据冗余问题(有损压缩)

第二帧数据 减去 第一帧的数据 的变化量压缩



整数离散余弦变化(DCT)：将空间上的相关性变为频域上无关的数据然后进行量化(无损压缩)

说明：把真正有数据的进行滤波， 滤波完成把所有数据集中到一块，另外一块全部变成0，减少后面处理数据的复杂度。

意义：把数据进行调整，更有利于后面的无损压缩。



CABAC压缩：根据上下文进行数据的压缩(无损压缩)

## 26.宏块

宏块是视频压缩操作的基本单元

无论是帧内压缩还是帧间压缩都是以宏块为基础单位



子块划分：

Mpeg2：将16x16  划分成4等块，每个是8x8

h264:每块只要存特定的数据



尺寸：

16x16 ， 8x16 ， 16x8 ， 8x8

8x8-> 8x8 ， 4x4 ， 4x8 ， 8x4



## 27.帧内压缩的理论(有损压缩)

相邻像素差别不大，所以可以进行宏块预测

人们对亮度的敏感度超过色度

YUV很容易将亮度与色度分开



针对的是: I、IDR 帧

## 28.帧内预测

通过9种模式预测：

...



帧内预测图像清晰度会差很多

解决：所以预测后，通过原始图与预测图进行残差值计算

进行压缩：预测模式信息压缩+残差值压缩

## 29.帧间压缩技术(有损压缩)

在同一个GOP中进行压缩

参考帧

运动估计(宏块匹配+运动矢量)：指的是一个过程，最终目的是找到运动矢量，用的方式是宏块匹配

运动补偿(解码)：找到残差值，在解码时将残差值补上去



针对的是P、B帧

## 30.宏块查找算法

三步搜索

二维对数搜索

四步搜索

钻石搜索



## 31.视频花屏原因

GOP分组中有帧丢失，会造成解码端的图像发生错误，这会出现马赛克

## 32.视频卡顿原因

为了避免花屏问题的发生，当发现有帧丢失时，就丢弃GOP内的所有帧，直到下一个IDR帧重新刷新图像，这样就能恢复了。

因为I帧时按周期来的，需要一个比较长的时间周期，如果在下一个I帧来之前不显示后来的头像，那么视频就静止不动了，这样就出现所谓的卡顿现象。

如果想卡顿的时间不要太长，可以多加一些IDR帧，1秒插1个IDR，那么顶多就卡1秒。这样就会造成数据量增加，会对带宽造成影响。



## 33.DCT变换（无损压缩）

DCT变换是指数据从分散到集中的一个过程。



经过有损压缩后，数据分散在二维图表中各个节点上，数据分散压缩比较困难，所以要进行DCT变换，

通过DCT变化会生成一个滤波，经过滤波处理所有分散的数据被集中到了一块。



## 34.VLC压缩(MPEG2)

可变长的编码。

使用率高的为短码，使用率低的为短码



## 35.CABAC压缩（H.264）

上下文适配二进制算数编码

编码后：前面的数据和VLC类似，但是随着时间的推移，后面的数据有上下文，所以数据非常小，压缩率就非常高。



## 36.H264编码流程

![yuv](.\image\h264_codec.png)

## 37.H264解码流程

![yuv](.\image\h264_encodec.png)



参考：

https://en.wikipedia.org/wiki/Advanced_Video_Coding



## 38.H264码流分层

NAL层：

Network Abstraction Layer 视频数据网络抽象层

在网络传输经常会丢包、延迟、乱序，有了NAL层，在接收端就知道有没有乱序或者丢失的情况，在根据各种情况进行处理。



VCL层：

Video Coding Layer 视频编码层



## 39.码流基本概念

SODB（String Of Data Bits） 二进制数据串

原始数据比特流，长度不一定是8倍，故需要补齐，它是由VLC层产生的



RBSP（Raw Byte Sequence Payload）原始字节序列载荷

SODB+trailing bits

算法是如果SODB最后一个字节不对齐，则补1和多个0



NALU NAL单元 

NAL Header(1B) + RBSP





## 40.码流封层

![yuv](.\image\h264_layer.png)

