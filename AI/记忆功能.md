# 记忆功能

## 实现思路

实现 LLM 记忆功能的思路是通过额外模块保存和管理对话历史。在每次与模型对话时，将人类和 AI 的历史对话插入到预设的 `chat_history` 占位符中，并将其作为上下文提供给模型。这样就能让模型在每次交互中“记住”之前的对话，确保更连贯的互动。



## 常见记忆模式

### 缓冲记忆

最基础的记忆模式，将所有 Human/Ai 生成的消息全部存储起来，每次需要使用时将保存的所有聊天消息列表传递到 Prompt 中，通过往用户的输入中添加历史对话信息/记忆，可以让 LLM 能理解之前的对话内容，而且这种记忆方式在上下文窗口限制内是无损的。

优点：

1. 无损记忆，用户输入什么内容都会被记忆；
2. 实现方式简单，兼容性最好，所有大模型都支持。

缺点：

1. 直接将存储的所有内容给 LLM，因为大量信息意味着新输入中包含更多的 Token，导致响应时间变慢和成本增加。
2. 当达到 LLM 的令牌数限制时，太长的对话无法被记住。
3. 记忆内容不是无限的，对于上下文长度较小的模型来说，记忆内容会变得极短。



### 缓冲窗口记忆

缓冲窗口记忆只保存最近的几次 Human/Ai 生成的消息，它基于 缓冲记忆 思想，并添加了一个窗口值 k，这意味着只保留一定数量的过去互动，然后“忘记”之前的互动。

优点：

1. 缓冲窗口记忆在限制使用的 Token 数量表现优异。
2. 对小模型也比较友好，不提问比较远的关联内容，一般效果最佳。
3. 实现方式简单，性能优异，所有大模型都支持。

缺点：

1. 缓冲窗口记忆不适合遥远的互动，会忘记之前的“互动”。
2. 部分对话内容长度较大，容易超过 LLM 的上下文限制。



### 令牌缓冲记忆

缓冲窗口记忆只保存限定次数 Human/Ai 生成的消息，它基于 缓冲记忆 思想，并添加了一个令牌数 max_tokens，当聊天历史超过令牌数时，会遗忘之前的互动。

优点：

1. 可以基于大语言模型的上下文长度限制分配记忆长度。
2. 对小模型也比较友好，不提问比较远的关联内容，一般效果最佳。
3. 实现方式简单，性能优异，所有大模型都支持。

缺点：

令牌缓冲记忆不适合遥远的互动，会忘记之前的“互动”。



### 摘要总结记忆

除了将消息传递给 LLM，还可以将消息进行总结，每次只传递总结的信息，而不是完整的消息。这种模式记忆对于较长的对话最有用，可以避免过度使用 Token，因为将过去的信息历史以原文的形式保留在提示中会占用太多的 Token。

优点：

1. 无论是长期还是短期的互动都可以记忆（模糊记忆）。
2. 减少长对话中使用 Token 的数量，能记忆更多轮的对话信息。
3. 长对话时效果明显，虽然最初使用 Token 数量较多，随着对话进行，摘要方法增长速度减慢，与常规缓冲内存模型相比具有优势。

缺点：

1. 虽然能同时记住近期和长远的互动内容，但是记忆的细节部分会丢失；
2. 对于较短的对话可能会增加 Token 使用量。
3. 对话历史的记忆完全依赖于中间摘要 LLM 的能力，需要为摘要 LLM 分配 Token，增加成本且未限制对话长度。



### 摘要缓冲混合记忆

摘要缓冲混合记忆结合了 摘要总结记忆 与 缓冲窗口记忆，它旨在对对话进行摘要总结，同时保留最近互动中的原始内容，但不是简单地清除旧的交互，而是将它们编译成摘要并同时使用，并且使用标记长度而不是交互数量来确定何时清除交互。

优点：

1. 无论是长期还是短期的互动都可以记忆，长期为模糊记忆，短期为精准记忆。
2. 减少长对话中使用 Token 的数量，能记忆更多轮的对话信息。

缺点：

1. 长期互动的内容仍然为模糊记忆。
2. 总结摘要部分完全依赖于中间摘要 LLM 的能力，需要为摘要 LLM 分配 Token，增加成本且未限制对话长度。



### 向量存储库记忆

将记忆存储在向量存储中，并在每次调用时查询前 K 个最匹配的文档。这类记忆模式能记住所有内容，在细节部分比摘要总结要强，但是比缓冲记忆弱，消耗 Token 方面相对平衡。

优点：

1. 拥有比摘要总结更强的细节，比缓冲记忆能记忆更多的内容，甚至无限长度的内容；
2. 消耗的 Token 也相对平衡；

缺点：

1. 性能相比其他模式相对较差，需要额外的 Embedding + 向量数据库支持。
2. 记忆效果受检索功能的影响，好的非常好，差的非常差。

 